{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENTIMENET ANALYSIS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT-ONwehKyCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygwwyr_bki4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdce5311-f5a8-48de-b1bb-5f7a5f166769"
      },
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "sess"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7efce9095400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwIeGSKIMBMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b66e951-05c0-4152-8b79-1d244c916684"
      },
      "source": [
        "vocab_size = 5000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)\n",
        "print(\"Len traning and testing, \",len(X_train), len(X_test))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Len traning and testing,  25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7VLOyWXMImf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "938cdf8f-92fe-4b1a-9c85-61607164f0c3"
      },
      "source": [
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "\n",
        "\n",
        "print('review with words')\n",
        "print([id2word.get(i, ' ') for i in X_train[2]])\n",
        "print('Label AS')\n",
        "print(y_train[6])"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review with words\n",
            "['cause', \"it's\", 'stick', 'passing', 'first', 'were', 'enjoys', 'for', 'from', 'look', 'seven', 'sense', 'from', 'me', 'and', 'die', 'in', 'character', 'as', 'and', 'issues', 'but', 'is', 'you', 'that', \"isn't\", 'one', 'song', 'just', 'is', 'him', 'less', 'are', 'strongly', 'not', 'are', 'you', 'that', 'different', 'just', 'even', 'by', 'this', 'of', 'you', 'there', 'is', 'eight', 'when', 'it', 'part', 'are', \"film's\", 'love', \"film's\", \"80's\", 'was', 'big', 'also', 'light', \"don't\", 'and', 'as', 'it', 'in', 'character', 'looked', 'cinematography', 'so', 'stories', 'is', 'far', 'br', 'man', 'acting']\n",
            "Label AS\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQLrNWagsNwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd8xESE0MVXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf12ea88-9cf8-485d-ebd2-f13ccaa2d60e"
      },
      "source": [
        "\"\"\"print(\"maximum review length \",len(max(X_train + X_test)))\n",
        "\n",
        "print(\"minimum review length \",len(min(X_train + X_test)))\"\"\""
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"maximum review length \",len(max(X_train + X_test)))\\n\\nprint(\"minimum review length \",len(min(X_train + X_test)))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnFeFpKAMWE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "max_words = 75\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PycO5RVkUdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f398c594-3b97-4c39-d59e-481e610c1324"
      },
      "source": [
        ""
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7efcebc782b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMYVeUZZNWxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "4760139d-2698-4aa6-f811-068158cb7e97"
      },
      "source": [
        "\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_size, input_length=max_words))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 75, 32)            160000    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-clMxnkOBRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "dcba1752-5bcf-440b-e9ee-368bfac5c900"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "batch_size = 64\n",
        "num_eps = 15\n",
        "\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_eps)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24936 samples, validate on 64 samples\n",
            "Epoch 1/7\n",
            "24936/24936 [==============================] - 50s 2ms/sample - loss: 0.1478 - acc: 0.9439 - val_loss: 0.5092 - val_acc: 0.8281\n",
            "Epoch 2/7\n",
            "24936/24936 [==============================] - 49s 2ms/sample - loss: 0.1196 - acc: 0.9555 - val_loss: 0.5685 - val_acc: 0.8125\n",
            "Epoch 3/7\n",
            "24936/24936 [==============================] - 48s 2ms/sample - loss: 0.1089 - acc: 0.9604 - val_loss: 0.5154 - val_acc: 0.8750\n",
            "Epoch 4/7\n",
            "24936/24936 [==============================] - 48s 2ms/sample - loss: 0.0913 - acc: 0.9689 - val_loss: 0.5788 - val_acc: 0.7969\n",
            "Epoch 5/7\n",
            "24936/24936 [==============================] - 48s 2ms/sample - loss: 0.0724 - acc: 0.9757 - val_loss: 0.6065 - val_acc: 0.8281\n",
            "Epoch 6/7\n",
            "24936/24936 [==============================] - 47s 2ms/sample - loss: 0.0627 - acc: 0.9799 - val_loss: 0.7532 - val_acc: 0.7812\n",
            "Epoch 7/7\n",
            "24936/24936 [==============================] - 47s 2ms/sample - loss: 0.0624 - acc: 0.9805 - val_loss: 0.8586 - val_acc: 0.7969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efcdbede240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBUzwplMOGus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4dbcb411-8438-444c-ecb2-fa2de1034f08"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy \" , scores[1])"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy  0.80508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cbcFMXfOU5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing\n",
        "def test(str):\n",
        "    st=str.lower().split()\n",
        "    list1=[]\n",
        "    for word in st:\n",
        "      if word.isalpha():\n",
        "        list1.append((word2id[word]))\n",
        "    \n",
        "    if len(list1)>75:\n",
        "      list1=list1[:75]\n",
        "\n",
        "    list2=[]\n",
        "    for i in range(75-len(list1)):\n",
        "      list2.append(0)\n",
        "    for i in list1 : \n",
        "        list2.append(i)\n",
        "    \n",
        "    return list2\n",
        "\n",
        "def predict(data):  \n",
        "    data=np.asarray(data)\n",
        "    data=data.reshape(1,75)\n",
        "    ynew = model.predict_classes(data)\n",
        "    if ynew==0:\n",
        "      print(\"Its a bad review\")\n",
        "    else:\n",
        "      print(\"Its good\")  \n",
        "    return ynew#returning ynew just for checking  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBNUecuTLvEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "76ef73e7-f45c-4298-e1bb-4f3431964595"
      },
      "source": [
        "str=\"Is this a better way to handle a movie . What a rubbish\"\n",
        "str=\"What a garbage movie it was. Its like a clearly excited 7- or 8-year-old kid sitting in front of me busted out crying and had to be whisked out of the theater by his father within the first five minutes .\"\n",
        "str=\"the movie is quiet awesome and its fantastic to have it\"\n",
        "word2id = imdb.get_word_index()\n",
        "\n",
        "l1=test(str)\n",
        "predict(l1)\n",
        "\n"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Its good\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZGRHSvkhBKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}