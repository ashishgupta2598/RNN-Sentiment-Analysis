{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENTIMENET_ANALYSIS_Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT-ONwehKyCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygwwyr_bki4H",
        "colab_type": "code",
        "outputId": "cdce5311-f5a8-48de-b1bb-5f7a5f166769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()#For GPU Avaliablity\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "sess"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7efce9095400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UejvrXhjz8q",
        "colab_type": "text"
      },
      "source": [
        "# IMDB Dataset \n",
        "IMDB dataset is used and vocal size taken is 5000\n",
        "# Info\n",
        "We will use a data-set consisting of 50000 reviews of movies from IMDB. Keras has a built-in function for downloading a similar data-set (but apparently half the size).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwIeGSKIMBMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "vocab_size = 5000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)#Load the training- and test-sets.\n",
        "print(\"Len traning and testing, \",len(X_train), len(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7VLOyWXMImf",
        "colab_type": "code",
        "outputId": "938cdf8f-92fe-4b1a-9c85-61607164f0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "word2id = imdb.get_word_index()#get_word_index() returns id assosicated with each index\n",
        "id2word = {i: word for word, i in word2id.items()}#To get back the word by using ID\n",
        "\n",
        "\n",
        "print('review with words')\n",
        "print([id2word.get(i, ' ') for i in X_train[2]])\n",
        "print('Label AS')\n",
        "print(y_train[6])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review with words\n",
            "['cause', \"it's\", 'stick', 'passing', 'first', 'were', 'enjoys', 'for', 'from', 'look', 'seven', 'sense', 'from', 'me', 'and', 'die', 'in', 'character', 'as', 'and', 'issues', 'but', 'is', 'you', 'that', \"isn't\", 'one', 'song', 'just', 'is', 'him', 'less', 'are', 'strongly', 'not', 'are', 'you', 'that', 'different', 'just', 'even', 'by', 'this', 'of', 'you', 'there', 'is', 'eight', 'when', 'it', 'part', 'are', \"film's\", 'love', \"film's\", \"80's\", 'was', 'big', 'also', 'light', \"don't\", 'and', 'as', 'it', 'in', 'character', 'looked', 'cinematography', 'so', 'stories', 'is', 'far', 'br', 'man', 'acting']\n",
            "Label AS\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQLrNWagsNwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd8xESE0MVXw",
        "colab_type": "code",
        "outputId": "cf12ea88-9cf8-485d-ebd2-f13ccaa2d60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"print(\"maximum review length \",len(max(X_train + X_test)))\n",
        "\n",
        "print(\"minimum review length \",len(min(X_train + X_test)))\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"maximum review length \",len(max(X_train + X_test)))\\n\\nprint(\"minimum review length \",len(min(X_train + X_test)))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnFeFpKAMWE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Max word means that our s entence should be max of length of 75 \n",
        "#If the sentece is >75 in length then Trim it or if its <75 then padding is done\n",
        "\n",
        "max_words = 75\n",
        "Xtrain = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PycO5RVkUdO",
        "colab_type": "code",
        "outputId": "f398c594-3b97-4c39-d59e-481e610c1324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7efcebc782b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHjo5vwanRFx",
        "colab_type": "text"
      },
      "source": [
        "#![Network Architecture](https://drive.google.com/file/d/1wI0nBOH7Gm45iRFifmdQ9K8uwPIBxSYG/view?usp=sharing)\n",
        "Link\n",
        "https://drive.google.com/file/d/1wI0nBOH7Gm45iRFifmdQ9K8uwPIBxSYG/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMYVeUZZNWxF",
        "colab_type": "code",
        "outputId": "9e3b5ca6-8c2c-439d-876d-cb80a41e230d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_size, input_length=max_words))\n",
        "model.add(GRU(units=16, return_sequences=True))\n",
        "model.add(GRU(units=8, return_sequences=True))\n",
        "model.add(GRU(units=4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 75, 32)            160000    \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 75, 16)            2352      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 75, 8)             600       \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 4)                 156       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 163,113\n",
            "Trainable params: 163,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-clMxnkOBRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adam optimizer is used \n",
        "#binary_crossentropy is taken as loss function \n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "batch_size = 64\n",
        "num_eps = 15\n",
        "\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_eps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBUzwplMOGus",
        "colab_type": "code",
        "outputId": "4dbcb411-8438-444c-ecb2-fa2de1034f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#accuracy \n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy \" , scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy  0.80508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtawYZPeqjb8",
        "colab_type": "text"
      },
      "source": [
        "#TESTING TIME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cbcFMXfOU5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing\n",
        "def test(str):\n",
        "    st=str.lower().split()#Convert the testing string to lowecase\n",
        "    list1=[]\n",
        "    for word in st:\n",
        "      if word.isalpha():\n",
        "        list1.append((word2id[word]))#Obtaning the corrosponding word_id of the words present\n",
        "        #Now list1 contatins the word_id in the  \n",
        "    \n",
        "    if len(list1)>75:#if the length of the word is >75 then Trim it to 75 \n",
        "      list1=list1[:75]\n",
        "\n",
        "    list2=[]\n",
        "    for i in range(75-len(list1)):#If the len<75 then add 0 at the end to make the length of the string upto 75\n",
        "      list2.append(0)\n",
        "    for i in list1 : #Append the 0's at the sentence\n",
        "        list2.append(i)\n",
        "    \n",
        "    return list2\n",
        "\n",
        "def predict(data):  \n",
        "    data=np.asarray(data)#list to numpy array\n",
        "    data=data.reshape(1,75)#reshaping \n",
        "    ynew = model.predict_classes(data)#Prediction of the data\n",
        "    if ynew==0:\n",
        "      print(\"Its a bad review\")\n",
        "    else:\n",
        "      print(\"Its good\")  \n",
        "    return ynew#returning ynew just for checking  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBNUecuTLvEz",
        "colab_type": "code",
        "outputId": "76ef73e7-f45c-4298-e1bb-4f3431964595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "str=\"Is this a better way to handle a movie . What a rubbish\"\n",
        "str=\"What a garbage movie it was. Its like a clearly excited 7- or 8-year-old kid sitting in front of me busted out crying and had to be whisked out of the theater by his father within the first five minutes .\"\n",
        "str=\"the movie is quiet awesome and its fantastic to have it\"\n",
        "word2id = imdb.get_word_index()\n",
        "\n",
        "l1=test(str)\n",
        "predict(l1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Its good\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZGRHSvkhBKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}